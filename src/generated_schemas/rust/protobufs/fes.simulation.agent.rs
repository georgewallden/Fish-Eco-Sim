// @generated
// This file is @generated by prost-build.
// --- AgentObservation ---
// Sent from the Simulation Engine to an AI Agent, describing what the agent perceives.

/// Represents a single perceived entity or stimulus in the agent's vicinity.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Percept {
    #[prost(enumeration="percept::EntityType", tag="1")]
    pub entity_type: i32,
    /// Optional: Unique ID of the perceived entity, if available and stable.
    /// Can be empty if the entity is transient or ID is not relevant for this percept.
    #[prost(string, tag="2")]
    pub entity_id: ::prost::alloc::string::String,
    /// Position of the perceived entity relative to the observing agent's current position.
    /// X-axis typically aligned with agent's forward direction or world X-axis depending on convention.
    /// For Alpha, let's assume world-relative offsets from agent's position for simplicity,
    /// or it could be in agent's local coordinate frame (forward is +Y, right is +X).
    /// Let's define it as: X relative to agent, Y relative to agent.
    /// If agent faces +Y world, then percept.relative_pos_y > 0 is in front.
    #[prost(float, tag="3")]
    pub relative_pos_x: f32,
    #[prost(float, tag="4")]
    pub relative_pos_y: f32,
}
/// Nested message and enum types in `Percept`.
pub mod percept {
    #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
    #[repr(i32)]
    pub enum EntityType {
        /// Default, should not typically be used.
        Unspecified = 0,
        Food = 1,
        /// For Alpha, could be any other agent.
        Agent = 2,
        /// Later, could be SAME_SPECIES, PREDATOR, PREY, etc.
        ///
        /// Represents an impassable boundary or obstacle.
        WallObstacle = 3,
    }
    impl EntityType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "ENTITY_TYPE_UNSPECIFIED",
                Self::Food => "ENTITY_TYPE_FOOD",
                Self::Agent => "ENTITY_TYPE_AGENT",
                Self::WallObstacle => "ENTITY_TYPE_WALL_OBSTACLE",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "ENTITY_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "ENTITY_TYPE_FOOD" => Some(Self::Food),
                "ENTITY_TYPE_AGENT" => Some(Self::Agent),
                "ENTITY_TYPE_WALL_OBSTACLE" => Some(Self::WallObstacle),
                _ => None,
            }
        }
    }
}
/// Contains all information an agent observes about itself and its environment
/// at a specific point in time. This is the input to the agent's decision-making process.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct AgentObservation {
    /// Agent's own state
    ///
    /// Current energy level of the agent.
    #[prost(float, tag="1")]
    pub current_energy: f32,
    /// Age of the agent in simulation ticks.
    #[prost(int64, tag="2")]
    pub current_age_ticks: i64,
    /// Agent's absolute X position in the world.
    #[prost(float, tag="3")]
    pub pos_x: f32,
    /// Agent's absolute Y position in the world.
    #[prost(float, tag="4")]
    pub pos_y: f32,
    /// Agent's current orientation in degrees (e.g., 0-360, with 0 being world +X or +Y).
    #[prost(float, tag="5")]
    pub orientation_degrees: f32,
    /// Sensory input: A list of perceived entities/stimuli.
    #[prost(message, repeated, tag="6")]
    pub percepts: ::prost::alloc::vec::Vec<Percept>,
    /// Optional: Reward received by the agent for its previous action.
    /// Often included in observations for reinforcement learning agents.
    /// float last_reward = 7; // For Alpha v1, maybe not essential if reward is handled separately.
    /// Let's include it as it's very common for DRL.
    #[prost(float, tag="7")]
    pub last_reward: f32,
}
// --- AgentAction ---
// Sent from an AI Agent to the Simulation Engine, specifying the agent's desired action.

/// Describes the action an agent intends to take in the next simulation step.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct AgentAction {
    /// Desired change in forward/backward movement.
    /// Positive values typically mean forward, negative could mean backward or be ignored
    /// if agents can only move forward. The magnitude can be speed or a normalized thrust.
    #[prost(float, tag="1")]
    pub move_delta: f32,
    /// Desired change in orientation in degrees.
    /// Positive values for turning one way (e.g., counter-clockwise), negative for the other.
    #[prost(float, tag="2")]
    pub turn_delta_degrees: f32,
    /// If true, the agent attempts to consume food if available at its current location/interaction range.
    #[prost(bool, tag="3")]
    pub attempt_eat: bool,
}
// @@protoc_insertion_point(module)
